{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor\nfrom sklearn.linear_model import LinearRegression, LogisticRegression\nfrom sklearn.model_selection import TimeSeriesSplit\nfrom sklearn.ensemble import VotingRegressor, GradientBoostingRegressor, RandomForestRegressor\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Считаем данные"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_data = pd.read_csv(\"../input/mai-ml-hw-models/Train.csv\")\ntest_data = pd.read_csv(\"../input/mai-ml-hw-models/Test.csv\")\nsample=pd.read_csv(\"/kaggle/input/mai-ml-hw-models/SampleSubmission.csv\")\n\n# https://github.com/Dyakonov/python_hacks/blob/master/dj_cat_coding.ipynb\nprint(train_data.columns)\ntrain_data.head()\n\n# Подготовка данных:\n# 1. Избавиться от даты\n# 2. Заполнить пропущенные значения\n# 3. Нагенерить новых фич\n# 4. Избавиться от выбросов","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(20,10))\nax.scatter(x = train_data['street_id'], y = train_data['price'])\nplt.ylabel('price', fontsize=12)\nplt.xlabel('street_id', fontsize=12)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Проверим, сколько пропущенных данных и какие\ntotal_missing = train_data.isna().sum().sum()\ntotal_cell = np.product(train_data.shape)\n\nprint(f\"missing values: {(total_missing / total_cell) * 100}%\")\n\ntrain_data.isna().mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Заполним пропуски\n# train_data[\"build_tech\"] = train_data[\"build_tech\"].fillna(0)\n# train_data.loc[train_data[\"build_tech\"] > 1, \"build_tech\"] = 1\n\n# train_data[\"metro_dist\"] = train_data[\"metro_dist\"].fillna(train_data[\"metro_dist\"].mean())\n\n# cond1 = train_data['floor'] > 8\n# cond2 = train_data['floor'] <= 8\n# train_data.loc[cond1,'g_lift'] = train_data.loc[cond1,'g_lift'].fillna(1.)\n# train_data.loc[cond2,'g_lift'] = train_data.loc[cond2,'g_lift'].fillna(0.)\n\ntotal_missing = train_data.isna().sum().sum()\ntotal_cell = np.product(train_data.shape)\n\nprint(f\"missing values: {(total_missing / total_cell) * 100}%\")\n\n# Удаляем выбросы\n# train_data = train_data.drop(train_data[(train_data['price'] > 80000000) & (train_data['build_tech'] == 2)].index)\ntrain_data = train_data[train_data['price'] < 70000000]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Аналогично заполним пропуски для test_data\n# test_data[\"build_tech\"] = test_data[\"build_tech\"].fillna(0)\n\n# test_data[\"metro_dist\"] = test_data[\"metro_dist\"].fillna(test_data[\"metro_dist\"].mean())\n\n# cond1 = test_data['floor'] > 8\n# cond2 = test_data['floor'] <= 8\n# test_data.loc[cond1,'g_lift'] = test_data.loc[cond1,'g_lift'].fillna(1.)\n# test_data.loc[cond2,'g_lift'] = test_data.loc[cond2,'g_lift'].fillna(0.)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def date_features(df):\n    df[\"quarter\"] = df.date.apply(lambda s: s.quarter)\n    df[\"month\"] = df.date.apply(lambda s: s.month)\n    df[\"week\"] = df.date.apply(lambda s: s.week)\n    df[\"day\"] = df.date.apply(lambda s: s.day)\n    df[\"dayofweek\"] = df.date.apply(lambda s: s.dayofweek)\n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.date = pd.to_datetime(train_data.date)\ntest_data.date = pd.to_datetime(test_data.date)\n\ntrain_data = date_features(train_data)\ntest_data = date_features(test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(15,8))\nax.scatter(x = train_data['area'], y = train_data['price'])\nplt.xlabel('area', fontsize=12)\nplt.ylabel('price', fontsize=12)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Сохраняем колонку с 'Id'\n# train_ID = train_data['id']\n# test_ID = test_data['id']\n\n\n\nY = train_data.price\nX = train_data.drop([\"id\", \"date\", \"price\"] , axis = 1)\n\n\ntest_X = test_data.drop([\"id\", \"date\"], axis = 1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tss = TimeSeriesSplit()\n\nfor train_index, test_index in tss.split(X):\n    X_train, X_test = X.iloc[train_index, :], X.iloc[test_index, :]\n    Y_train, Y_test = Y.iloc[train_index], Y.iloc[test_index]\n    \nx_train, x_test, y_train, y_test = X_train, X_test, Y_train, Y_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = test_X\n\nreg1 = XGBRegressor(\n    max_depth=12,\n    n_estimators=9000,\n    min_child_weight=6,\n    colsample_bytree=1, \n    subsample=1, \n    eta=1.4,\n    n_jobs=6,\n    booster='gbtree',\n    reg_alpha=1,\n    reg_lambda=1,\n    random_state=2,\n    learning_rate=0.1\n)\n\nreg1.fit(\n    x_train, \n    y_train, \n    eval_metric='rmse', \n    eval_set=[(x_train, y_train), (x_test, y_test)], \n    early_stopping_rounds = 10)\n\n# reg2 = RandomForestRegressor(\n#     n_estimators=9000, #\n#     criterion='mse', # \n#     max_depth=12, #\n#     min_samples_split=12, \n#     min_samples_leaf=6, \n#     max_features='auto', # \n#     bootstrap=True, #\n#     oob_score=False, #\n#     n_jobs=6, # \n#     random_state=2 #\n# )\n\n\n# Создаём ансамбль моделей\n# ereg = VotingRegressor(estimators=[('gb', reg1), ('rf', reg2)])\n\n# Обучаем ансамбль\n# ereg = ereg.fit(\n#     x_train,\n#     y_train\n# )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.shape)\nprint(X_test.shape)\nprint(sample.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Делаем предсказания\ny_pred = reg1.predict(X_test)\n\nsample['price'] = y_pred\nsample.to_csv(\"res.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}